{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84ba7cb-037d-468b-af22-32bae592f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QC.utils import shell_do\n",
    "import os\n",
    "import subprocess\n",
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3d3dae-3604-4806-908f-0d8b17025f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geno = '/data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex'\n",
    "out = '/data/vitaled2/test_data/mcgill'\n",
    "\n",
    "# ref_path = '/data/vitaled2/GenoTools/ref'\n",
    "# check_bim_pl_script = f'{ref_path}/HRC-1000G-check-bim.pl'\n",
    "# ref_panel_path = f'{ref_path}/PASS.Variantsbravo-dbsnp-all.tab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d47b6-c412-4a71-835e-c439e09aa39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3c2201-e70d-4931-82ea-556e53a42614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download file to check\n",
    "# bash1 = \"wget http://www.well.ox.ac.uk/~wrayner/tools/HRC-1000G-check-bim.v4.2.5.zip -P \" + out_path\n",
    "# bash2 = \"unzip \" + out_path + \"HRC-1000G-check-bim.v4.2.5.zip -d \" + out_path\n",
    "# bash3 = \"wget ftp://ngs.sanger.ac.uk/production/hrc/HRC.r1-1/HRC.r1-1.GRCh37.wgs.mac5.sites.tab.gz -P \" + out_path\n",
    "# bash4 = \"gunzip \" + out_path + \"HRC.r1-1.GRCh37.wgs.mac5.sites.tab.gz\"\n",
    "\n",
    "# bashes = [bash1,bash2,bash3,bash4]\n",
    "\n",
    "# for bash in bashes:\n",
    "#     shell_do(bash)\n",
    "\n",
    "# !curl 'https://bravo.sph.umich.edu/freeze3a/hg19/download/all' -H 'Accept-Encoding: gzip, deflate, br' -H 'Cookie: remember_token=\"dan@datatecnica.com|439f5115690bc00f69ad686507220d3892abfcaadd650f8b9ead3362b0bb9a9fa95448f933e724f97f70f48b271a637c47414b10dbd99b6af8a1303353cdf5cf\"' --compressed > {ref_path}/bravo-dbsnp-all.vcf.gz\n",
    "# !wget https://www.well.ox.ac.uk/~wrayner/tools/CreateTOPMed.zip -P {ref_path}\n",
    "# !unzip /data/vitaled2/GenoTools/ref/CreateTOPMed.zip -d {ref_path}\n",
    "# !gunzip {ref_path}/PASS.Variantsbravo-dbsnp-all.tab.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad987619-9d08-4039-a96d-59dfa0b5ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data_prep(geno_path, out_path, ref_panel='ref/PASS.Variantsbravo-dbsnp-all.tab'):\n",
    "\n",
    "    '''\n",
    "    info here:\n",
    "    https://www.well.ox.ac.uk/~wrayner/tools/\n",
    "    '''\n",
    "    \n",
    "    check_bim_pl_script = 'ref/HRC-1000G-check-bim.pl'\n",
    "    workdir = os.getcwd()\n",
    "    os.chdir(out_path)\n",
    "\n",
    "    plink1 = f'plink --bfile {geno_path} --freq --out {geno_path}'\n",
    "    check_bim_cmd = f'perl {check_bim_pl_script} -b {geno_path}.bim -f {geno_path}.frq -r {ref_panel} -h'\n",
    "    bash1 = 'sh Run-plink.sh'\n",
    "\n",
    "    cmds = [plink1, check_bim_cmd, bash1]\n",
    "\n",
    "    for cmd in cmds:\n",
    "        shell_do(cmd)\n",
    "\n",
    "    os.chdir(workdir)\n",
    "    \n",
    "    mk_vcf_cmds = [f'plink --bfile {geno_path}-updated-chr{str(i)} --recode vcf --chr {str(i)} --out {geno_path}_chr{str(i)}' for i in range(1,24)]   \n",
    "\n",
    "    for cmd in mk_vcf_cmds:\n",
    "        shell_do(cmd)\n",
    "\n",
    "    # ## then sort and zip\n",
    "    sort_zip_cmds = [f'vcf-sort {geno_path}_chr{str(i)}.vcf | bgzip -c > {geno_path}_pre_impute_chr{str(i)}.vcf.gz' for i in range(1,24)]\n",
    "\n",
    "    for cmd in sort_zip_cmds:\n",
    "        subprocess.run(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "    \n",
    "    vcf_outpaths = [f'{geno_path}_pre_impute_chr{str(i)}.vcf.gz' for i in range(1,24)]\n",
    "    return {'vcfs': vcf_outpaths}\n",
    "\n",
    "\n",
    "def check_impute_status(token, job_id):\n",
    "        \n",
    "    # imputation server url\n",
    "    url = 'https://imputation.biodatacatalyst.nhlbi.nih.gov/api/v2'\n",
    "\n",
    "    # add token to header (see authentication)\n",
    "    headers = {'X-Auth-Token' : token }\n",
    "\n",
    "    # get all jobs\n",
    "    r = requests.get(url + \"/jobs\", headers=headers)\n",
    "    if r.status_code != 200:\n",
    "        raise Exception('GET /jobs/ {}'.format(r.status_code))\n",
    "\n",
    "    status = r.json()\n",
    "    for stat in status['data']:\n",
    "        if stat['id'] == job_id:\n",
    "            if stat['state'] == 1:\n",
    "                print(\"Launching Job:\", stat['id'])\n",
    "            elif stat['state'] == 2:\n",
    "                print(\"Running Job:\", stat['id'])\n",
    "            elif stat['state'] == 3:\n",
    "                print(stat['id'], \"returned state '3', have a look at jobs on the web front for more information\")\n",
    "            elif stat['state'] == 5:\n",
    "                print(stat['id'], \"has failed. consult docs on data input to ensure your vcfs are correct\")\n",
    "            elif stat['state'] == 4:\n",
    "                print(stat['id'], \"COMPLETED!\")\n",
    "\n",
    "            return stat['state']\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        \n",
    "def pull_imputed_data(out_path, token, job_id, password):\n",
    "    \n",
    "    workdir = os.getcwd()\n",
    "    os.chdir(out_path)\n",
    "    \n",
    "    # imputation server url\n",
    "    url = 'https://imputation.biodatacatalyst.nhlbi.nih.gov/api/v2'\n",
    "\n",
    "    # add token to header (see authentication)\n",
    "    headers = {'X-Auth-Token' : token }\n",
    "\n",
    "    r = requests.get(f'{url}/jobs/{job_id}', headers=headers)\n",
    "    if r.status_code != 200:\n",
    "        raise Exception(f'GET /jobs/ {r.status_code}')\n",
    "\n",
    "    output_json = r.json()\n",
    "\n",
    "    hashes_dict = {output_json['outputParams'][i]['id'] : output_json['outputParams'][i]['hash'] for i in range(len(output_json['outputParams']))}\n",
    "\n",
    "    # run a curl for each\n",
    "    curls = [f'curl -sL https://imputation.biodatacatalyst.nhlbi.nih.gov/get/{str(key)}/{str(hashes_dict[key])} | bash' for key in hashes_dict]\n",
    "    \n",
    "    for curl in curls:\n",
    "        print(f\"Curling output data with the following command: {curl}\")\n",
    "        subprocess.run(curl, shell=True)\n",
    "    print() \n",
    "    print(\"Finished Pulling Imputed Data!\")\n",
    "    print()\n",
    "    \n",
    "    os.chdir(workdir)\n",
    "    \n",
    "\n",
    "def submit_job(vcf_list, server='topmed', password='imputer', token=None):\n",
    "    # test topmed server\n",
    "    url = 'https://imputation.biodatacatalyst.nhlbi.nih.gov/api/v2'\n",
    "    \n",
    "    # add token to header (see Authentication)\n",
    "    headers = {'X-Auth-Token' : token}\n",
    "\n",
    "    open_vcfs = [open(vcf, 'rb') for vcf in vcf_list]\n",
    "\n",
    "    files = set([('input-files-upload', vcf) for vcf in open_vcfs])\n",
    "    # files = {'input-files': open(vcf_list[0], 'rb')}\n",
    "\n",
    "    data = {'input-mode' : 'imputation',\n",
    "            'input-files-source': 'file-upload',\n",
    "            'input-password': password,\n",
    "            'input-refpanel': 'apps@topmed-r2@1.0.0',\n",
    "            'input-phasing': 'eagle',\n",
    "            'input-population': 'all'}\n",
    "\n",
    "    r = requests.post(url + \"/jobs/submit/imputationserver\", files=files, headers=headers, data=data)\n",
    "    if r.status_code != 200:\n",
    "        raise Exception('POST /jobs/submit/imputationserver {}'.format(r.status_code))\n",
    "\n",
    "    job_id = r.json()['id']\n",
    "    message = r.json()['message']\n",
    "    print(job_id, message)\n",
    "    \n",
    "    print('***************************')\n",
    "    print('* * * * * * * * * * * * * *')\n",
    "    \n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def run_imputation(vcf_list, out_path, password, token):\n",
    "    \n",
    "    job_json = submit_job(vcf_list, token=token)\n",
    "    job_id = job_json['id']\n",
    "    \n",
    "    imp_state = 0\n",
    "    while imp_state < 3:\n",
    "        time.sleep(600)\n",
    "        os.system('clear')\n",
    "        imp_state = check_impute_status(token, job_id)\n",
    "\n",
    "        if imp_state == 4:\n",
    "            print(\"Pulling Completed Data from Imputation Server!\")\n",
    "            pull_imputed_data(out_path=out_path, token=token, job_id=job_id, password=password)\n",
    "    \n",
    "    return job_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e206f660-0fa0-486d-bee9-d30ee9df90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /data/vitaled2/test_data/mcgill/imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94679808-e3b5-4458-973d-98bb1893dfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex --freq --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex\n",
      "Executing: perl ref/HRC-1000G-check-bim.pl -b /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex.bim -f /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex.frq -r ref/PASS.Variantsbravo-dbsnp-all.tab -h\n",
      "Executing: sh Run-plink.sh\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr1 --recode vcf --chr 1 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr1\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr2 --recode vcf --chr 2 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr2\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr3 --recode vcf --chr 3 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr3\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr4 --recode vcf --chr 4 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr4\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr5 --recode vcf --chr 5 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr5\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr6 --recode vcf --chr 6 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr6\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr7 --recode vcf --chr 7 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr7\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr8 --recode vcf --chr 8 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr8\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr9 --recode vcf --chr 9 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr9\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr10 --recode vcf --chr 10 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr10\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr11 --recode vcf --chr 11 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr11\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr12 --recode vcf --chr 12 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr12\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr13 --recode vcf --chr 13 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr13\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr14 --recode vcf --chr 14 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr14\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr15 --recode vcf --chr 15 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr15\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr16 --recode vcf --chr 16 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr16\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr17 --recode vcf --chr 17 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr17\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr18 --recode vcf --chr 18 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr18\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr19 --recode vcf --chr 19 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr19\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr20 --recode vcf --chr 20 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr20\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr21 --recode vcf --chr 21 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr21\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr22 --recode vcf --chr 22 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr22\n",
      "Executing: plink --bfile /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex-updated-chr23 --recode vcf --chr 23 --out /data/vitaled2/test_data/mcgill/MCGILL_all_callrate_sex_chr23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job-20210621-204729-289 Your job was successfully added to the job queue.\n",
      "***************************\n",
      "* * * * * * * * * * * * * *\n",
      "Launching Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "Running Job: job-20210621-204729-289\n",
      "job-20210621-204729-289 COMPLETED!\n",
      "Pulling Completed Data from Imputation Server!\n",
      "Curling output data with the following command: curl -sL https://imputation.biodatacatalyst.nhlbi.nih.gov/get/323927/9d23f0da8c7171e900a6dc20b9890a10661d850f89a23adc838e18b44ea44a97 | bash\n",
      "Curling output data with the following command: curl -sL https://imputation.biodatacatalyst.nhlbi.nih.gov/get/323931/49b3181bd5637038ffa68648c000b00566a42085f6691d85167c20bfa508161f | bash\n",
      "Curling output data with the following command: curl -sL https://imputation.biodatacatalyst.nhlbi.nih.gov/get/323933/e07763ef06e378fbe0feb7a6863f16ac404f971c60eae9641d564c36f43bd53c | bash\n",
      "Curling output data with the following command: curl -sL https://imputation.biodatacatalyst.nhlbi.nih.gov/get/323934/c0e2264b01ebee3a02ccd599147a3db185203fd1ff6d832c8ef86c63464951df | bash\n",
      "\n",
      "Finished Pulling Imputed Data!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'id': 'job-20210621-204729-289',\n",
       " 'message': 'Your job was successfully added to the job queue.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = 'eyJjdHkiOiJ0ZXh0XC9wbGFpbiIsImFsZyI6IkhTMjU2In0.eyJtYWlsIjoidml0YWxlZDJAbmloLmdvdiIsImV4cGlyZSI6MTYyNjQwNjczMzc5OCwibmFtZSI6IkRhbiBWaXRhbGUiLCJhcGkiOnRydWUsInVzZXJuYW1lIjoidml0YWxlZDIifQ.hcHyBgJmcTZDEpFnb8t5gH1lfxSZQZHC4Lu9IhN0E18'\n",
    "imputed_out = f'{out}/imputed'\n",
    "impute_data = impute_data_prep(geno, out)\n",
    "run_imputation(impute_data['vcfs'], imputed_out, password='imputer', token=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28b13c0e-ad54-4671-a286-470ef9e59e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curling output data with the following command: curl -sL https://imputation.biodatacatalyst.nhlbi.nih.gov/get/322730/1a2c05d4879a154fe8e76d09476a5807d24525a504a0c0929b1359f3799768f3 | bash\n",
      "Curling output data with the following command: curl -sL https://imputation.biodatacatalyst.nhlbi.nih.gov/get/322734/9520f9b23ff03166bf61e257bce7a3c21d864b06a1ab256d8198a318fbade616 | bash\n",
      "Curling output data with the following command: curl -sL https://imputation.biodatacatalyst.nhlbi.nih.gov/get/322736/5d6889d44ef669eda2ef4ebc1d3c7109bb7c755be5240b43bc3d473dcf8da3f2 | bash\n",
      "Curling output data with the following command: curl -sL https://imputation.biodatacatalyst.nhlbi.nih.gov/get/322737/ac5b2653ada5dc257b6b272d14626766ab027be87ddfcbd1ddc4f3ed380fbe92 | bash\n",
      "\n",
      "Finished Pulling Imputed Data!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pull_imputed_data(out_path=imputed_out, token=key, job_id='job-20210618-214638-236',password='imputer')\n",
    "# pull_imputed_data(out_path, token, impute_id, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8fce29-76d5-471f-8e78-b3252a918b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# mcgill_vcf_list = [f'{geno_path}_pre_impute_chr{str(i)}.vcf.gz' for i in range(1,24)]\n",
    "\n",
    "\n",
    "\n",
    "# def check_impute_status(token, impute_id):\n",
    "        \n",
    "#     # imputation server url\n",
    "#     url = 'https://imputation.biodatacatalyst.nhlbi.nih.gov/api/v2'\n",
    "\n",
    "#     # add token to header (see authentication)\n",
    "#     headers = {'X-Auth-Token' : token }\n",
    "\n",
    "#     # get all jobs\n",
    "#     r = requests.get(url + \"/jobs\", headers=headers)\n",
    "#     if r.status_code != 200:\n",
    "#         raise Exception('GET /jobs/ {}'.format(r.status_code))\n",
    "\n",
    "#     status = r.json()\n",
    "#     for stat in status['data']:\n",
    "#         if stat['id'] == impute_id:\n",
    "#             if stat['state'] == 1:\n",
    "#                 print(\"Launching Job:\", stat['id'])\n",
    "#             elif stat['state'] == 2:\n",
    "#                 print(\"Running Job:\", stat['id'])\n",
    "#             elif stat['state'] == 3:\n",
    "#                 print(stat['id'], \"returned state '3', have a look at jobs on the web front for more information\")\n",
    "#             elif stat['state'] == 5:\n",
    "#                 print(stat['id'], \"has failed. consult docs on data input to ensure your vcfs are correct\")\n",
    "#             elif stat['state'] == 4:\n",
    "#                 print(stat['id'], \"COMPLETED!\")\n",
    "\n",
    "#             return stat['state']\n",
    "\n",
    "#         else:\n",
    "#             pass\n",
    "\n",
    "# def pull_imputed_data(out_path, token, impute_id, password):\n",
    "\n",
    "#     # imputation server url\n",
    "#     url = 'https://imputation.biodatacatalyst.nhlbi.nih.gov/api/v2'\n",
    "\n",
    "#     # add token to header (see authentication)\n",
    "#     headers = {'X-Auth-Token' : token }\n",
    "\n",
    "#     r = requests.get(f'{url}/jobs/{_id}', headers=headers)\n",
    "#     if r.status_code != 200:\n",
    "#         raise Exception(f'GET /jobs/ {r.status_code}')\n",
    "\n",
    "#     output_json = r.json()\n",
    "\n",
    "#     hashes_dict = {output_json['outputParams'][i]['id'] : output_json['outputParams'][i]['hash'] for i in range(len(output_json['outputParams']))}\n",
    "\n",
    "#     # run a curl for each\n",
    "#     curls = [f'curl -sL https://imputation.biodatacatalyst.nhlbi.nih.gov/get/{str(key)}/{str(hashes_dict[key])} | bash' for key in hashes_dict]\n",
    "    \n",
    "#     for curl in curls:\n",
    "#         print(f\"Curling output data with the following command: {curl}\")\n",
    "#         subprocess.run(curl, shell=True)\n",
    "#     print() \n",
    "#     print(\"Finished Pulling Imputed Data!\")\n",
    "#     print()\n",
    "    \n",
    "\n",
    "# def impute(vcf_list, out_path, server='topmed', password='imputer', token=None)\n",
    "#     # test topmed server\n",
    "#     url = 'https://imputation.biodatacatalyst.nhlbi.nih.gov/api/v2'\n",
    "    \n",
    "#     # add token to header (see Authentication)\n",
    "#     headers = {'X-Auth-Token' : token}\n",
    "\n",
    "#     open_vcfs = [open(vcf, 'rb') for vcf in vcf_list]\n",
    "\n",
    "#     files = set([('input-files-upload', vcf) for vcf in open_vcfs])\n",
    "#     # files = {'input-files': open(vcf_list[0], 'rb')}\n",
    "\n",
    "#     data = {'input-mode' : 'imputation',\n",
    "#             'input-files-source': 'file-upload',\n",
    "#             'input-password': password,\n",
    "#             'input-refpanel': 'apps@topmed-r2@1.0.0',\n",
    "#             'input-phasing': 'eagle',\n",
    "#             'input-population': 'all'}\n",
    "\n",
    "#     r = requests.post(url + \"/jobs/submit/imputationserver\", files=files, headers=headers, data=data)\n",
    "#     if r.status_code != 200:\n",
    "#         raise Exception('POST /jobs/submit/imputationserver {}'.format(r.status_code))\n",
    "\n",
    "#     impute_id = r.json()['id']\n",
    "#     message = r.json()['message']\n",
    "#     print(impute_id, message)\n",
    "    \n",
    "#     print('***************************')\n",
    "#     print('* * * * * * * * * * * * * *') \n",
    "        \n",
    "#     imp_state = 0\n",
    "#     while imp_state < 3:\n",
    "#         time.sleep(600)\n",
    "#         os.system('clear')\n",
    "#         imp_state = check_impute_status(token, impute_id)\n",
    "\n",
    "#         if imp_state == 4:\n",
    "#             print(\"Pulling Completed Data from Imputation Server!\")\n",
    "#             pull_imputed_data(token, impute_id, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ece491-8a6e-4aa7-81b5-12244410f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def impute_make_vcf(geno_path, out_path):\n",
    "# then make vcf files\n",
    "# def make_vcfs(plink_paths)\n",
    "#     step1 = \"RECODE PLINK FILES TO VCF\"\n",
    "#     mk_vcf_cmds = [f'plink --bfile {geno_path}-updated-chr{str(i)} --recode vcf --chr {str(i)} --out {geno_path}_chr{str(i)}' for i in range(1,24)]   \n",
    "\n",
    "#     for cmd in mk_vcf_cmds:\n",
    "#         shell_do(cmd)\n",
    "\n",
    "#     # ## then sort and zip\n",
    "#     step2 =  \"vcf-sort AND bgzip VCFS\"\n",
    "#     sort_zip_cmds = [f'vcf-sort {geno_path}_chr{str(i)}.vcf | bgzip -c > {geno_path}_pre_impute_chr{str(i)}.vcf.gz' for i in range(1,24)]\n",
    "\n",
    "#     for cmd in sort_zip_cmds:\n",
    "#         subprocess.run(cmd, stdout=subprocess.PIPE, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1369f9e9-aa85-426e-9249-49de8dc3d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#     #now unzip all \".zip\" files (one for each chromosome)\n",
    "#     zip_list = glob.glob('{out_path}/imputed/*.zip')\n",
    "#     unzip_cmds = ['unzip -P ' + pw + ' ' + file for file in zip_list]\n",
    "\n",
    "#     for cmd in unzip_cmds:\n",
    "#         print(\"Unzipping: \" + cmd)\n",
    "#         subprocess.run(cmd, shell=True)\n",
    "#     print(\"Finished Unzipping\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25881bec-95b0-47f3-9b27-bf788e54f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def impute(self, key, input_population='eur', pw='imputer', vcf_list=None):\n",
    "#         geno_path = self.geno_path\n",
    "#         vcf_list = self.vcf_list_for_impute\n",
    "        \n",
    "#         # imputation server url\n",
    "#         url = 'https://imputationserver.sph.umich.edu/api/v2'\n",
    "\n",
    "#         # add token to header (see Authentication)\n",
    "#         headers = {'X-Auth-Token' : key}\n",
    "\n",
    "#         open_vcfs = [open(vcf, 'rb') for vcf in vcf_list]\n",
    "        \n",
    "#         files = set([('input-files-upload', vcf) for vcf in open_vcfs])\n",
    "\n",
    "#         data = {'input-mode' : 'imputation',\n",
    "#                 'input-files-source': 'file-upload',\n",
    "#                 'input-password': pw,\n",
    "#                 'input-refpanel': 'apps@hrc-r1.1',\n",
    "#                 'input-phasing': 'eagle',\n",
    "#                 'input-population': input_population}\n",
    "\n",
    "#         r = requests.post(url + \"/jobs/submit/minimac4\", files=files, headers=headers, data=data)\n",
    "#         if r.status_code != 200:\n",
    "#             raise Exception('POST /jobs/submit/minimac4 {}'.format(r.status_code))\n",
    "        \n",
    "#         impute_id = r.json()['id']\n",
    "#         message = r.json()['message']\n",
    "\n",
    "#         print(message)\n",
    "#         print(impute_id)\n",
    "#         print('***************************')\n",
    "#         print('* * * * * * * * * * * * * *') \n",
    "        \n",
    "#         imp_state = 0\n",
    "#         while imp_state < 3:\n",
    "#             time.sleep(60)\n",
    "#             os.system('clear')\n",
    "#             imp_state = self.check_impute_status(key, impute_id)\n",
    "            \n",
    "#             if imp_state == 4:\n",
    "#                 print(\"Pulling Completed Data from Imputation Server!\")\n",
    "#                 self.pull_imputed_data(key, impute_id, pw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
